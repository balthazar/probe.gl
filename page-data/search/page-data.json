{"componentChunkName":"component---node-modules-ocular-gatsby-src-templates-search-jsx","path":"/search","webpackCompilationHash":"9f8e174fe10f6c04867b","result":{"pageContext":{"isCreatedByStatefulCreatePages":false,"data":[{"excerpt":"Introduction A collection of JavaScript front-end debugging tools A JavaScript logging library focused on facilitating debugging and…","rawMarkdownBody":"# Introduction\n\nA collection of JavaScript front-end debugging tools\n\n* A JavaScript logging library focused on facilitating debugging and performance instrumentation of front-end applications.\n* A benchmark rig to help measure and track regressions of critical functions\n* Test drivers to help do automated browser testing from node\n\n\n## Comparison with other Logging Solutions\n\nproble.gl's focus on debugging and performance instrumentation of front-end applications has lead to different design choices and priorities compared with logging libraries that are designed for facilitating logging of production code in back-end services. Those libraries are often focused on integrating with various logging backends (log to file, log to server, etc) and not on integrating with the browser console and the front-end debugging workflow.\n\n\n## Features\n\n* **Off by default** - probe.gl makes efforts to have a minimal performance footprint when not enable, to let you consider leaving your probes switched off in production code.\n* **Lightweight** - probe.gl is designed to have a small impact on application bundle size and to avoid dependencies on other modules.\n\n\n### Logging Support\n\nThe basic logging support provided by probe.gl is simple but surprisingly useful.\n\n* **Priority levels** - Your logs will only be displayed when the user has enabled probe.gl and the specified priority level has been set.\n* **Defeats log cascades** - Caches warnings to ensure only one of each warning is emitted to avoid flooding the console.\n* **Readable assert Errors** - Reformats `assert` messages to show actual error string\n* **Image Logging** - Images can be logged to console (Chrome only)\n* **Source Code Links** - Clicking probe.gl log messages in the browser console takes you to the source code line where the probe function was called, even though you are not calling `console` methods directly.\n\n\n### Profiling Support\n\nInstrument your applications by adding probes to get timings in browser console or in node. The probes then collect data about your application when you run it.\n\n* **High-Resolution Timers** - probe.gl uses the best available timers on the platform, such as `window.performance.now()` and `hrtime` to get better than millisecond timings.\n* **Multiple Timers** - Your \"probes\" automatically log both time since operation start and delta time since last probe.\n* **External Timers** - Timing metrics received e.g. from a server can be presented as part of client side timings.\n\n\n### Persistent Configuration\n\nprobe.gl offers a basic persistent configuration system:\n\n* **Persistent Configuration** - probe.gl persists its configuration in local storage, so you can restart your app without having to change settings, speeding up debugging.\n* **Extensible Configuration** - flags and values in probe.gl's configuration are available to your app. Built-in options include enabling probe, setting log level, help etc.\n\n\n### Cross platform support\n\n* **Supports Node and Browser** - Use with confidence in code that runs in both environments (e.g. test suites or isomorphic React apps).\n* **Auto-detects platform APIs** - Uses the best available versions of platform-dependent facilities like high resolution timers, console methods etc.\n* **Limited impact on global state** - Other than some light polyfills for `console` and a global reference to the probe library, the lib doesn't modify global state.\n\n\n### Debug Features\n\ndebug related facilities, such as console log interception, global context in debugger etc.\n\n\n### Benchmarking Support\n\nIn addition to in-app profiling, probe also supports a simple benchmarking rig\n\n* **Benchmark Suite** - function to run a suite of functions and collect data\n* **Persist and Compare Benchmarks** -\n\n\n## History\n\nprobe.gl serves as the common instrumentation and logging library for frameworks in the Uber Visualization Suite.\n\nThe 'probe' part of the name relates to the concept of instrumenting your application by injecting \"probes\" (i.e. information collection checkpoints) into its source code. The suffix '.gl' is added to hint that this library is associated with the suite, rather than to signal any dependency on WebGL.\n\n\n","slug":"docs","title":"Introduction"},{"excerpt":"What's New v3.1 Release Date: TBD, Sep 2019 (Beta Release Available) probe.gl  - Stats objects can now be constructed with a type hint for…","rawMarkdownBody":"# What's New\n\n## v3.1\n\nRelease Date: TBD, Sep 2019 (Beta Release Available)\n\n### **probe.gl**\n\n- `Stats` - Stats objects can now be constructed with a type hint for each stat. This is used to select default formatters for the stats.\n- `StatsWidget` - Can now be created without a stats object, and the stats object can be replaced and unset.\n\n### **@probe.gl/test-utils**\n\n- Input event emulation API\n\n\n## v3.0\n\nRelease Date: Apr, 2019\n\n## Module split\n\nThe subfile import scheme has been replaced with proper npm modules:\n\n* **probe.gl** - Log Class\n* **@probe.gl/bench** - Benchmark utilities\n* **@probe.gl/stats-widget** - UI widgets for profiling\n* **@probe.gl/test-utils** - Integration test utilities\n\n## Bench class\n\n* **Benchmark async functions** - New method `Bench.addAsync`.\n\n## Utilities\n\n* New method `getHiResTimestamp` - Uses high res timer APIs in both browser and Node.\n\n\n## v2.1\n\nRelease Date: Jan 2019\n\n### Log class additions\n- New method `log.assert()`\n- New method `log.settings()`\n- New method `log.set()`\n- New method `log.get()`\n\n## v1.0\n\nprobe.gl is now open source!\n","slug":"docs/whats-new","title":"What's New"},{"excerpt":"About Benchmarking probe.gl offers a  facility that makes it easy to create \"micro-benchmarks\" for optimization and regression testing…","rawMarkdownBody":"# About Benchmarking\n\nprobe.gl offers a `Bench` facility that makes it easy to create \"micro-benchmarks\" for optimization and regression testing purposes.\n\n## Goals\n\n* Fast benchmarking - Assumes benchmarks are run frequently and need to run fast. Sacrifice some precision for fast results (configurable)\n* Reporting - Want to copy your benchmarks into reports? You can provide custom formatters, or use exiting formatters like the markdown formatter.\n* Priority - As with everything in probe.gl, you can assign a priority to each bench case, e.g. enabling a quick run of top level test cases, or a drill down run that benches multiple variations.\n* Regression - Automatically stores values from previous runs and compares the current run against them.\n* Browser and Node - As always, probe.gl makes sure that your benchmarks will run under Node.js as well as in the browser (be aware that performance can differ quite a bit between the two).\n\n\n## What is a \"Micro Benchmark\"\n\nA micro benchmark is simply a function you supply, that will be run for a number of times with a timer to determine how many times per second it can be executed.\n\n\n## Structure of a Benchmark Suite\n\nInstantiate the `Bench` class to create a benchmark suite. use `bench.group` to group bench cases and add headers. Use `bench.add` to register individual benchmarks.\n\n","slug":"docs/articles/about-benchmarking","title":"About Benchmarking"},{"excerpt":"Console Logging This doc is a WIP Probe API Signature A probe.gl function invocation typically looks like this: There are a lot of…","rawMarkdownBody":"# Console Logging\n\n> This doc is a WIP\n\n### Probe API Signature\n\nA probe.gl function invocation typically looks like this:\n```js\nlog.probe(priority, message, ...args)();\n```\n\nThere are a lot of conventions and built-in capabilities. The following sections contains observations about this signature and provide more background about what is going on.\n\n\n### Why Double Function Calls?\n\nA distinctive aspect of the probe API is the requirement for double function calls, i.e. the extra parenthesis at the end of `log.probe``(...)()`. The double function calls ensure that the Chrome browser console's clickable links are generated correctly. Thanks to these double parentheses you can click on a probe in the Chrome console and \"go\" directly to the probe call in your application source code.\n\nThe double parenthesis is a rather unusual JavaScript programming idiom and if you forget it nothing will be logged. Therefore probe.gl will keep track of whether a returned log function was called and warn you next time you call probe if it wasn't.\n\n\n### Log Priority\n\nA basic feature of probe.gl is that you can assign a `priority` threshold to each probe. The term `priority` can seem a little counter-intuitive at first, as specifying a higher value in your probes actually make them less likely to \"fire\". The basic idea is that a probe will only \"fire\" if the log priority is greater than or equal to the probe's priority.\n\nBecause of this most probe.gl APIs take a `priority` parameter as a first argument.\n\n| `0` | Unconditional. Always fires. errors and warnings are priority `0` by default. |\n| `1` | Fires . |\n| `2` | Always fires. |\n| `3` | Always fires. |\n| `4` | Always fires. |\n\nNote that regardless of log level, probes will only fire assuming probe itself is enabled.\n\n\n### Log Options\n\nThe `priority` parameter is an overloaded parameter that can be supplied in the following ways:\n* `priority` can be ommitted entirely. In this case, `priority` defaults to `0`, which means that the probe is executed / printed regardless of log level.\n* `priority` can be a `Number`, in which case it is used as the `priority` threshold of this probe, which will only \"fire\" if the log priority is greater than or equal to this value.\n* `priority` can be an `Object`, in which case it is used as the `priority` threshold of this probe. It will only \"fire\" if the log priority is greater than or equal to this value.\n\n* `priority` (`Number`) - as above, if not supplied defaults to `0` (fires unconditonally if probe is enabled).\n* `once` (`Boolean`|`Number`) - if `true`, the argument string will be cached and this log will only be fired once. If a number, this is the minimum amount of seconds between logging the same message.\n\n\n### Log Message\n\nMany probe.gl API calls take a `message` parameter. This `message` is an overloaded parameter that can be either a string or a function that returns a string, which will be called every time the probe fires.\n\nThe main purpose of supporting functions is to avoid situations where a message string is being generated even when the probe doesn't fire:\n\nA typical inconvenience when logging is unwanted performance impact when generating dynamic log messages. In the case below, the string template literal is being generated every time the line executes, *even when logging is disabled*:\n```js\nlog.probe(1, `${object} has ${value}`)();\n```\nWith probe, the solution is easy:\n```js\nlog.probe(1, () => `${object} has ${value}`)();\n```\nNow the performance overhead of the probe is again minimized.\n\n\n### Log Parameters\n\nMost probe method accept a variable number of additional arguments at the end of the function call. These arguments will be passed directly to the underlying console method. This allows you to leverage the built-in Chrome console printing mechanisms for e.g. Objects and Arrays (these allow you to expand and descend into objects).\n\n\n## Probe Timings\n\n\n## Types of Probes\n\n### Groups\n\nChrome provides a wonderful grouping feature that allows us to organize logs in expandable headers.\n\n### Tables\n\nChrome provides a table logging method\n\n### Images\n\nUnder Chrome it is possible to log images to the console, using a rather involved styling trick. `log.image` will be a no-op under all other environments.\n\n\n\n\n","slug":"docs/articles/about-logging","title":"Console Logging"},{"excerpt":"About Testing probe.gl provides a set of test utilities intended to facilitate typical testing tasks. Browser Test Automation A key part of…","rawMarkdownBody":"# About Testing\n\nprobe.gl provides a set of test utilities intended to facilitate typical testing tasks.\n\n\n## Browser Test Automation\n\nA key part of the test utilities is a framework for automating browser tests using puppeteer. The intention is to make browser tests invokable from the terminal by e.g. `package.json` scripts, by spawning a browser and waiting until the test results are available, then closing the browser and reporting back the results to the shell script.\n\n* `BrowserDriver` is a relatively low-level class that provides a `Promise` based interface to `puppeteer` as well as facilities for spawning a \"dev server\" and communicating status via exit codes back to the invoking shell. This class is intended as a building block for custom automation tasks.\n* `BrowserTestDriver` is a subclass of `BrowserDriver` that is intended to be a \"turn-key\" solution for typical browser set.\n\n\n## Function Spys\n\nprobe.gl provides a `makeSpy` function that enable you to check if your functions were called during exection of test code.\n\n\n## Visual Regression Testing\n\nprobe.gl provides a set of experimental image loading and diffing tools. Together with the Automation facilities it is possible to create sophisticated visual regression tests. More to come...","slug":"docs/articles/about-testing","title":"About Testing"},{"excerpt":"Problems with Console Logging Whether to use a library like probe.gl to improve on the browser's built-in console logging tends to be a…","rawMarkdownBody":"# Problems with Console Logging\n\nWhether to use a library like probe.gl to improve on the browser's built-in console logging tends to be a personal preference, and people tend to have strong opinions on the matter. The question is obvious: the browser already provides a logging facility, why spend effort and code bloat wrapping it?\n\nTo illustrate some of the problems probe.gl is attempting to solve, let's consider how one would write a simple logging wrapper for an app that had started logging using the \"raw\" console API.\n\n```js\nfunction app() {\n  console.debug('hello world')\n}\n```\n\nLet's say we want a function that logs conditionally (only if a `priority` has been set), and only issues a warning once to avoid flooding the console. A first attempt could look like this\n\n```js\nfunction log(priority, message) {\n  if (priority <= logPriority)\n  \tif (!cache[message]) {\n  \t  console.debug(message);\n  \t}\n  }\n}\n...\napp() {\n  log(1, 'hello world');\n}\n```\n\nSome issues with this:\n* Now the log message in Chrome console no longer let's you click back to the application. Instead it links back to the log function.\n\nIn addition:\n* console.debug is not available in Node.js and certain browsers.\n","slug":"docs/articles/issues-with-logging","title":"Problems with Console Logging"},{"excerpt":"Roadmap We are still iterating on probe.gl. Here are some of the ideas, in very rough form... In-memory log: Instead of, or in addition to…","rawMarkdownBody":"# Roadmap\n\nWe are still iterating on probe.gl. Here are some of the ideas, in very rough form...\n\n- **In-memory log:** Instead of, or in addition to, logging to the console, `Probe.probe` now saves to an internal array of log messages. This allows you to turn console output off and do post-facto reporting or visualization.\n\n- **Persistent settings and saved logs** - Local storage configuration now allows for persistent configuration (including enable/disable) across browser sessions, and makes it easier to have Probe disabled (or enabled, for developers) in production. This also makes it easy to set additional development flags like `isNewFeatureEnabled`. Usage via the JS console:\n```\nProbe.enable().configure({level: 2, useMyDevFeature: true});\n```\n\n- **Better Console groups** - Probe.groups allows independently time execution of parallel activities, using console groups to organize the output.\n\n- **Duration:** Including `start` and `end` in the metadata object allows Probe\no calculate duration between calls using the same `name`:\n```\nProbe.probe('long_process', {start: true});\ndoLongProcess();\nProbe.probe('long_process', {end: true});\n```\n\n## Done\n\n- **Console output links back to app** - Makes Chrome console's links point to application source code instead of Probe's source code, making it possible to click on a Probe log in the console and open the line that generated it. To achieve this, Probe methods now return log functions that app calls by applying a \"()\" function invocation.\n","slug":"docs/roadmap","title":"Roadmap"},{"excerpt":"Installation","rawMarkdownBody":"# Installation\n\n```js\nnpm install probe.gl\n```\n","slug":"docs/get-started","title":"Installation"},{"excerpt":"StatsWidget A widget that displays the state of a probe.gl Stats object to screen. Usage Create a  HTML element to display tracked . Each…","rawMarkdownBody":"# StatsWidget\n\nA widget that displays the state of a probe.gl [Stats](/docs/api-reference/log/stats.md) object to screen.\n\n## Usage\n\nCreate a `StatsWidget` HTML element to display tracked `Stats`. Each `Stat` can\nbe associated with a `formatter` that indicates how it should be displayed.\n\n```js\nimport React, {Component} from 'react';\nimport {Stats} from 'probe.gl';\nimport StatsWidget from '@probe.gl/stats-widget';\n\nclass App extends Component {\n  componentDidMount() {\n    this._stats = new Stats({\n      id: 'My Stats'\n    });\n    \n    this._statsWidget = new StatsWidget(this._stats, {\n      container: this._containerRef\n    });\n\n    this.setState({intervalId: setInterval(this._update, 300)});\n  }\n\n  componentWillUnmount() {\n    // use intervalId from the state to clear the interval\n    clearInterval(this.state.intervalId);\n  }\n\n  _update() {\n    // create a stat with name and type\n    const counter = this._stats.get('Counter', 'count');\n    counter.incrementCount();\n    this._statsWidget.update();  \n  }\n\n  render() {\n    return (<div ref={_ => this._containerRef = _}/>);\n  }\n}\n\n```\n\n## Methods\n\n### constructor\n\n`new StatsWidget(stats, options)`\n\n* `stats` (`Stats`) - a probe.gl [Stats](/docs/api-reference/log/stats.md) instance.\n* `options`: (`Object`)\n  - `title` (`String`) - header text for the widget. Defaults to the `id` of the `Stats` object.\n  - `framesPerUpdate` (`Number`) - number of times `update` must be called before the widget is re-rendered. Allows the application\n   to call `update` each frame with re-renders occurring at a slower rate.\n  - `container` (DOMElement) - DOM element to use as container for the widget. Will be created internally if not provided.\n  - `css` (`Object`) - css properties to apply to the container `div` of the widget. Two special keys can be used to modify the\n   style of nested elements:\n    + `header` (`Object`) - css properties to apply to the header `div` of the widget.\n    + `item` (`Object`) - css properties to apply to the individual item `div`s for each stat displayed in the widget.\n  - `formatters` (`Object`) - text formatters to use to display a stat. Keys are the stat's `name`. Value can either be\n   a function that takes a single `stat` object as argument, or one of the following strings:\n    + `count`: Display as a simple count.\n    + `averageTime`: Display average time.\n    + `totalTime`: Display total time.\n    + `fps`: Display Hz as a frame rate.\n    + `memory`: Display count as a memory measurement.\n    `resetOnUpdate` (`Object`) - whether the a stat should be reset each time the widget is re-rendered. Keyed by the stat's `name`.\n\n### setStats\n\nSet Stats object rendered by the widget.\n\nParameters:\n\n* `stats` () - [`Stats`](https://github.com/uber-web/probe.gl/blob/master/docs/api-reference/log/stats.md) Object.\n\n\n### setFormatter\n\nSet the formatter associated with a given stat.\n\n`statsWidget.setFormatter(name, formatter)`\n\n* `name` (`String`, required) - the name of the stat to associate with a formatter.\n* `formatter` (`Function`, required) - function that takes a `Stat` object and returns a string.\n\n\n### update\n\n`statsWidget.update()`\n\nRerender the widget.\n","slug":"docs/api-reference/stats-widget/stats-widget","title":"StatsWidget"},{"excerpt":"BrowserDriver (Test Automation Class) A Chrome Browser test automation driver class (based on the Chrome  protocol via the  module. The…","rawMarkdownBody":"# BrowserDriver (Test Automation Class)\n\n<p class=\"badges\">\n  <img src=\"https://img.shields.io/badge/Node.js-v8.0+-blue.svg?style=flat-square\" alt=\"Node\" />\n  <img src=\"https://img.shields.io/badge/Chrome-v64+-blue.svg?style=flat-square\" alt=\"Node\" />\n</p>\n\nA Chrome Browser test automation driver class (based on the [Chrome `DevTools` protocol](https://chromedevtools.github.io/devtools-protocol/) via the [`puppeteer`](https://github.com/GoogleChrome/puppeteer) module. The `BrowserDriver` class is primarily intended for automating browser based applications from shell scripts.\n\nA `BrowserDriver` is typically used to do the following:\n* Launch/close a Chromium browser instance\n* Start/stop a local web service.\n* Opens a browser page with a URL in the browser.\n\nTo use this class, [puppeteer](https://www.npmjs.com/package/puppeteer) must be installed as a dev dependency.\n\n## Usage\n\n```js\nconst {BrowserDriver} = require('@probe.gl/test-utils');\nnew BrowserDriver({id: 'browser-test'});\n```\n\n\n## Constructor\n\n```js\nconst browserDriver = new BrowserDriver(opts);\n```\n\nParameters:\n\n* `opts` (Object)\n  - `id` (String) - an id for this `BrowserDriver` instance. Default `browser-driver`.\n\n\n## Methods\n\n### startBrowser(options : Object)\n\nLaunch a new browser instance.\n\n`options` are directly passed to [puppeteer.launch](https://github.com/GoogleChrome/puppeteer/blob/v1.11.0/docs/api.md#puppeteerlaunchoptions).\n\nReturns a `Promise` that resolves when the browser has started.\n\n### openPage(options : Object)\n\nOpen a new tab in the browser. Only works after a browser instance is started:\n\n```js\nbrowserDriver.startBrowser().openPage({url: 'http://localhost'});\n```\n\nParameters:\n\n* `url` (String) - The url to load in the page. Default `http://localhost`.\n* `exposeFunctions` (Object) - keys are function names to be added to the page's `window` object, and the values are callback functions to execute in Node.js. See [exposeFunction](https://github.com/GoogleChrome/puppeteer/blob/v1.11.0/docs/api.md#pageexposefunctionname-puppeteerfunction) for details.\n* `onLoad` (Function) - callback when the page is loaded\n* `onConsole` (Function) - callback when the page logs to console\n* `onError` (Function) - callback if the puppeteer page crashes\n\nReturns a `Promise` that resolves when the page is open.\n\n\n### stopBrowser()\n\nTerminate the browser instance.\n\nReturns a `Promise` that resolves when the browser is closed.\n\n\n### startServer(config : Object)\n\nRuns a server in a new child process, that the browser can connect to.\n\n```js\ndriver.startServer({\n  command: './node_modules/.bin/webpack-dev-server',\n  arguments: ['--config', 'webpack.config.js'],\n  wait: 2000\n})\n```\n\nParameters:\n\n* `command` (String) - the command to run, default `'webpack-dev-server'`.\n* `arguments` (Array<String>) - a list of string arguments.\n* `options` (Object) - options for the new process. Default `{maxBuffer: 5000 * 1024}`. See [child_process.spawn](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options) for details.\n* `port` (`'auto'`|`false`) - `startServer` can attempt to bind the service to an available port if `port` is set to `'auto'`. In this case, the command receives additional arguments `--port <port>`. Default `'auto'`.\n* `wait` (Number) - time in milliseconds to wait after executing the command. If any error is generated from the child process during this period, the `Promise` will reject. Otherwise, the service is considered available. Default `2000`.\n\nReturns a `Promise` that resolves to the service URL when the server is available.\n\n\n### stopServer()\n\nStops the server (kills the child process).\n\nReturns: a `Promise` that resolves when the server is closed.\n\n\n### exit(statusCode : Number)\n\nExit the process after safely closing down any running browser and server instances.\n\nParameter:\n\n* `statusCode` - the status code to use when exit the process. Default `0`.\n","slug":"docs/api-reference/test-utils/browser-driver","title":"BrowserDriver (Test Automation Class)"},{"excerpt":"Usage Configure instrumentation level using URL parameters. Probe can be enabled in code or in the Chrome console at runtime. Because Probe…","rawMarkdownBody":"# Usage\n\n## Configure instrumentation level using URL parameters.\n\nProbe can be enabled in code or in the Chrome console at runtime. Because Probe\nstores its state in a cookie, enabling or disabling Probe or specific options\npersists across browser sessions.\n\nEnable Probe logging and features:\n```\nProbe.enable();\n```\n\nSet levels:\n```\nProbe.setLevel(2);\n```\n\nMost Probe config methods are chainable:\n```\nProbe.enable().setLevel(2).configure({isPrintEnabled: false});\n```\n\n### Read configuration to enable/disable features in development\n\nIn your code:\n```\nimport Probe from `probe.gl`;\n\nif (Probe.getOption('myFeature')) {\n  enableFeature();\n}\n```\n\nIn the console, for development testing:\n```\nProbe.configure({mySnazzyFeature: true});\n```\n\n### Probe and production code\n\nProbe is designed so that you have the option of keeping your instrumentation\nin production code. Unless you enable Probe, all Probe methods effectively\nbecome no-ops.\n\n### Access to Probe in the debugger\n\nProbe does not attach itself to the `window` context by default. You may want to\ndo this when your app is initialized:\n\n```\nimport Probe from `probe.gl`;\nwindow.Probe = Probe;\n```\n\n### Access to your own functions in the debugger\n\nIf you want to access your functions in the browser console, simply attach\nthem to the Probe scope and they will be available on the `Probe` global\nvariable.\n\n```\nimport AppStore from './store';\nProbe.getAppState() {\n  console.log(JSON.stringify(AppStore.getState(), null, '  '));\n}\n```\n\n### Profiling Support\n\nProfiling is primary purpose of the probe library. It has a complement of\nmethods (i.e. \"probes\") that you can add to your application to log\ntimings. Each method comes in several variants, which correspond to three\ndifferent log levels, allowing you to control the amount of log detail\nby setting the probe level.\n\n\n#### Cross-Module Profiling\n\nProbe uses global data to ensure that you are working\nagainst the same clocks even if you happen to load multiple instances\nor versions of the probe module in different modules.\n\n\n### Warning and Error Handlers\n\nProbe contains a number of optional console intercepts that can be\nenabled to:\n* Treat warnings as hard errors (i.e exceptions that can trigger breakpoints)\n* Break on warnings and errors (Probe can trigger the debugger directly)\n* Detect rejected promise errors - optionally\n  calling window.onerror with the error or calling the proposed\n  rejected promise handler.\n","slug":"docs/get-started/adding-probes","title":"Usage"},{"excerpt":"BrowserTestDriver (Test Automation Class) A higher level helper class that inherits the . Primarily intended for automating browser tests…","rawMarkdownBody":"# BrowserTestDriver (Test Automation Class)\n\n<p class=\"badges\">\n  <img src=\"https://img.shields.io/badge/Node.js-v8.0-blue.svg?style=flat-square\" alt=\"Node\" />\n  <img src=\"https://img.shields.io/badge/Chrome-v64+-blue.svg?style=flat-square\" alt=\"Node\" />\n</p>\n\nA higher level helper class that inherits the [`BrowserDriver`](./docs/api-reference/test/browser-task-status). Primarily intended for automating browser tests from Node.js shell scripts.\n\nA `BrowserTestDriver` starts a Chromium browser instance and a server and opens a page with a URL that loads a script from the server. The script that runs in the browser is expected to report test results back using predefined global functions.\n\nTo use this class, [puppeteer](https://www.npmjs.com/package/puppeteer) and [pixelmatch](https://www.npmjs.com/package/pixelmatch) must be installed as dev dependencies.\n\n## Usage\n\nIn your node.js start script:\n\n```js\n// This is the script that runs in Node.js and starts the browser\nconst {BrowserTestDriver} = require('@probe.gl/test-utils');\nnew BrowserTestDriver().run({\n  server: {\n    command: 'webpack-dev-server',\n    arguments: ['--env.browser-test']\n  },\n  headless: true\n});\n```\n\nIn your script that is run on the browser:\n\n```js\n// Run test cases\n...\n// App is done running, terminate the browser instance\nwindow.browserTestDriver_finish('All tests passed');\n```\n\n\n## Constructor\n\n```js\nconst browserTestDriver = new BrowserTestDriver(opts);\n```\n\nParameters:\n\n* `opts` (Object)\n  - `id` (String) - an id for this `BrowserTestDriver` instance. Default `browser-driver`.\n\n\n## Methods\n\n### run(config : Object)\n\nRuns the tests:\n\n* Starts a Chromium browser instance.\n* Starts a dev server, e.g. a webpack-dev-server that bundles a test script.\n* Opens a browser page to run the test script.\n* Extracts test reports from the browser back into node\n* Closes browser, server and terminates the current node script.\n* Passes an exit status (e.g. pass/fail) back to the invoking shell.\n\nParameters:\n\n* `title` (String) - name of the test, e.g. `'Unit tests'`. Default `'Browser Test'`.\n* `headless` (Boolean) - whether to run the test in headless mode. If `true`, all console outputs from the test app will be piped to the shell. If `false`, the browser window will remain open for debugging.\n* `server` (Object|Function|`false`)\n  - If an object is supplied: used as options to create a dev server. Passed to [BroserDriver.startServer](/docs/api-reference/test-utils/browser-driver.md).\n  - If a function is supplied: will be called to create a dev server. Should return a `Promise` that resolves to the service URL.\n  - If `false`: no dev server.\n* `browser` (Object) - options to user for creating the Puppeteer instance. Passed to [BroserDriver.startBrowser](/docs/api-reference/test-utils/browser-driver.md).\n* `exposeFunctions` (Object) - keys are function names to be added to the page's `window` object, and the values are callback functions to execute in Node.js. See [exposeFunction](https://github.com/GoogleChrome/puppeteer/blob/v1.11.0/docs/api.md#pageexposefunctionname-puppeteerfunction) for details.\n* `url` (String) - if supplied, will be used instead of the URL returned by the dev server.\n\n\n## Built-in Exposed Globals\n\nThe `BrowserTestDriver` instance exposes a series of global functions to the browser application.\nThe following functions can be called from the browser application to communicate with the nodejs script:\n\n### browserTestDriver_fail()\n\n```js\nwindow.browserTestDriver_fail();\n```\n\nNotify the node script that some test has failed.\n\n### browserTestDriver_finish(message : String)\n\n```js\nwindow.browserTestDriver_finish('Congratulations! All tests passed.');\n```\n\nNotify the node script that the app has finished executing and the browser should be closed.\n\n### browserTestDriver_isHeadless\n\n```js\nif (window.browserTestDriver_isHeadless) {\n  console.log('Test is running in headless mode');\n}\n```\n\nTruthy if the current test environment is headless.\n\n\n### browserTestDriver_captureAndDiffScreen(options : Object)\n\n```js\nwindow.browserTestDriver_captureAndDiffScreen({\n  goldenImage: './golden-images/map.png',\n  region: {x: 0, y: 0, width: 800, height: 600},\n  threshold: 0.99\n}).then(result => {\n  // do something\n});\n```\n\nRequest a pixel diff between the current page and a reference \"golden image.\" This can be used to verify that the page is visually rendered as expected.\n\n* `goldenImage` (String) - path to the golden image, relative to the directory where the shell command is executed\n* `region` (Object, optional) - a bounding box to take a screenshot of. In shape of `{x, y, width, height}` relative to the page. If not specified, will take a screenshot of the whole page.\n* `threshold` (Number, optional) - the matching score for the test to pass. Between `0` (no pixels matched) to `1` (all pixels matched). Default `0.99`.\n* `tolerance` (Number, optional) - the tolerance when comparing two pixels. Between `0` (strict color match) to `1` (anything will pass). Default `0.1`.\n* `includeAA` (Boolean, optional) - If `true`, all pixels are compared. Otherwise detect and ignore anti-aliased pixels. Default `false`.\n* `createDiffImage` (Boolean, optional) - if `true`, will generate binary image data that highlight the mismatched pixels. Default `false`.\n* `saveOnFail` (Boolean, optional) - if `true`, any screenshots that failed to meet the target matching rate will be saved to disk for further investigation. Default `false`.\n* `saveAs` (String, optional) - the filename to save the screenshot as. If the string contains `[name]`, it will be replaced by the golden image path. Default `[name]-failed.png`.\n\nReturns: a `Promise` that resolves to an object with the following fields:\n\n* `success` (Boolean) - whether the test passed. A test can fail either because the matching score is lower than the specified `threshold`, or an unexpected error occurred.\n* `headless` (Boolean) - whether the browser was running in headless mode.\n* `match` (Number) - the matching score. Between `0` (no pixels matched) to `1` (all pixels matched).\n* `matchPercentage` (String) - `match` formatted in percentage form.\n* `diffImage` (Uint8Array) - image data that highlight the mismatched pixels. Only if `createDiffImage: true`.\n* `error` (String) - error message if any.\n\n\n### browserTestDriver_emulateInput(event: Object)\n\n```js\nwindow.browserTestDriver_emulateInput({\n  type: 'keypress',\n  key: 's',\n  ctrlKey: true\n}).then(result => {\n  // ctrl + S is pressed! do something\n});\n```\n\nDispatch an emulated user input to the page. The following event types are supported:\n\n#### keypress\n\nPress a key on the keyboard.\n\n- `type: 'keypress'`\n- `key` (String) - see https://github.com/GoogleChrome/puppeteer/blob/master/lib/USKeyboardLayout.js\n- `delay` (Number) - the time between keydown and keyup. Default `0`.\n- `shiftKey` (Boolean) - whether to press the key with the shift key down. Default `false`.\n- `ctrlKey` (Boolean) - whether to press the key with the control key down. Default `false`.\n- `metaKey` (Boolean) - whether to press the key with the meta key down. Default `false`.\n\n\n#### click\n\nClick the mouse at a given screen coordinate.\n\n- `type: 'click'`\n- `x` (Number) - the screen x of the click.\n- `y` (Number) - the screen y of the click.\n- `button` (String) - `'left'`, `'right'` or `'middle'`.\n- `delay` (Number) - the time between mousedown and mouseup. Default `0`.\n- `shiftKey` (Boolean) - whether to click with the shift key down. Default `false`.\n- `ctrlKey` (Boolean) - whether to click with the control key down. Default `false`.\n- `metaKey` (Boolean) - whether to click with the meta key down. Default `false`.\n\n\n#### mousemove\n\nMove the mouse to a given screen coordinate.\n\n- `type: 'mousemove'`\n- `x` (Number) - the screen x to move the pointer to.\n- `y` (Number) - the screen y to move the pointer to.\n- `steps` (Number) - how many intermediate mousemove events to generate, default `1`.\n\n\n#### drag\n\nDrag the mouse from a given screen coordinate to another.\n\n- `type: 'drag'`\n- `startX` (Number) - the screen x to drag from.\n- `startY` (Number) - the screen y to drag from.\n- `endX` (Number) - the screen x to drag to.\n- `endY` (Number) - the screen y to drag to.\n- `button` (String) - `'left'`, `'right'` or `'middle'`.\n- `steps` (Number) - how many intermediate mousemove events to generate, default `1`.\n- `shiftKey` (Boolean) - whether to drag with the shift key down. Default `false`.\n- `ctrlKey` (Boolean) - whether to drag with the control key down. Default `false`.\n- `metaKey` (Boolean) - whether to drag with the meta key down. Default `false`.\n","slug":"docs/api-reference/test-utils/browser-test-driver","title":"BrowserTestDriver (Test Automation Class)"},{"excerpt":"Benchmarking Using probe.gl to create a benchmark suite.","rawMarkdownBody":"# Benchmarking\n\nUsing probe.gl to create a benchmark suite.","slug":"docs/get-started/benchmarking","title":"Benchmarking"},{"excerpt":"Using Probe while Debugging Probe makes a global variable  available in the browser console. This variable holds an object with methods that…","rawMarkdownBody":"# Using Probe while Debugging\n\nProbe makes a global variable `window.Probe` available in the browser console. This variable holds an object with methods that you can call directly in the allows you to interact with `Probe` to enable and disable flags (or Probe itself), you can change the log priority etc.\n\n```\n> window.Probe\n...\n> window.Probe.enable()\n> window.Probe.setLogPriority()\n```\n\n## Probe Commands\n\n### Enabling and Disabling\n\n### Changing Log Priority\n","slug":"docs/get-started/using-while-debugging","title":"Using Probe while Debugging"},{"excerpt":"Bench Bench is a benchmark harness class that allows you to organize a number of benchmarks / performance tests into a Benchmark suite that…","rawMarkdownBody":"# Bench\n\nBench is a benchmark harness class that allows you to organize a number of benchmarks / performance tests into a Benchmark suite that can be executed with a single comment. Each test is registered with and `id` which allows `Bench` to do compare results across runs and perform limited regression testing.\n\n\n## Usage\n\n```js\nimport {Bench} from '@probe.gl/bench';\n\nconst bench = new Bench()\n  .group('Utility tests')\n  .add('Math.sqrt', () => Math.sqrt(100))\n  ;\n\nbench.run();\n```\n\n## Methods\n\n### constructor\n\n`new Bench({})`\n* timeouts = true,\n* log = console.log.bind(console)\n\n### group(id)\n\nAdds a group header.\n\n`bench.group(id)`\n\n### add\n\nAdds a test case. Supports multiple signatures\n\n`bench.add(priority, id, initFunc, testFunc)`\n`bench.add(priority, id, testFunc)`\n`bench.add(id, initFunc, testFunc)`\n`bench.add(id, testFunc)`\n\n* `priority`=`0` (Number, optional) - allows controlling which bench cases execute.\n* `id` (String)\n* `initFunc` (Function, options) -\n* `testFunc` (Function, options) -\n\n## addAsync\n\nAdds an async test case. Use when `testFunc` returns a promise. Supports same signatures as `add`.\n\n### run()\n\n`bench.run()`\n\n### calibrate\n\n`bench.calibrate(id, func1, func2, opts)`\n","slug":"docs/api-reference/bench/bench","title":"Bench"},{"excerpt":"Log A simple console wrapper with a host of features Safely exposes advanced features of Chrome and Firefox console APIs, as well as Node.js…","rawMarkdownBody":"# Log\n\nA simple console wrapper with a host of features\n* Safely exposes advanced features of Chrome and Firefox console APIs, as well as Node.js color logging, by providing fallbacks for missing methods in other environments.\n* Conditional logging - includes a log levels system (aka priorities) that can be controller in the browser console, and settings persist through browser reloads.\n* Defeats log cascades - Caches warnings to ensure only one instance of each warning is emitted\n* Links to log calls in browser console - Clicking on a log message shows the code that called the log function.\n* Image logging - In Chrome console, it is possible log images\n* Improved `assert` messages - Reformats errors from `assert` to show actual error string\n\n\n## Usage\n\nCreate a new Log\n```js\nimport {Log} from 'probe.gl';\nconst log = new Log({id: 'my-app'});\nlog.log('Hello world')();  // <<< Note: double function call, is necessary\n```\n\nAdd color (only affects output in Node.js)\n```js\nimport {Log, COLOR} from 'probe.gl';\n...\nlog.log({message: 'Hello world', color: COLOR.GREEN});\n```\n\nLog using a message generating function, rather than string (avoid creating message when not needed)\n```js\nlog.log(2, () => `${expensiveFunction()}`)();\n```\n\n## Types and Parameters\n\n### Log Function Parameters\n\nLog functions can be called with different parameter combinations\n- `log.log(message, ...args)` - priority defaults to 0\n- `log.log(priority, message, ...args)` - sets priority\n- `log.log({message, ...options})` - additional options can be set, priority is zero\n- `log.log({priority, message, args, ...options})` - additional options can be set\n\n\n### Log Function Options\n\nWhen using named parameters (passing an object as first parameter), the following options can be used:\n\n| Option       | Type          | Description |\n| ---          | ---           | ---         |\n| `priority`   | `Number`      | This probe will only \"fire\" if the log's current priority is greater than or equal to this value.defaults to `0`, which means that the probe is executed / printed regardless of log level. |\n| `time`       | `Boolean`     | Add a timer since page load (default for `Log.probe`) |\n| `once`       | `Boolean`     | Logs this message only once (default for `Log.warn`, `Log.once` |\n| `tag`        | `String`      | Optional tag |\n| `color`      | `enum|String` | Node.js only: Basic colors like `green`, `blue` and `red` are supported, currently only for console logging. For safe to use constants, use the COLOR enumeration, see below. |\n| `background` | `enum|String` | Node.js only: Colors the background of the character. |\n\n\n### Log Messages\n\nThe `message` argument can be a string or a function returning a string.\n\n\n### Colors\n\nTo get access to color definitions:\n`import {COLOR} from 'probe.gl'`\n\nAvailable colors:\n* `COLOR.BLACK`, `COLOR.RED`, `COLOR.GREEN`, `COLOR.YELLOW`, `COLOR.BLUE`, `COLOR.MAGENTA`, `COLOR.CYAN`, `COLOR.WHITE`\n* `COLOR.BRIGHT_BLACK`, `COLOR.BRIGHT_RED`, `COLOR.BRIGHT_GREEN`, `COLOR.BRIGHT_YELLOW`, `COLOR.BRIGHT_BLUE`, `COLOR.BRIGHT_MAGENTA`, `COLOR.BRIGHT_CYAN`, `COLOR.BRIGHT_WHITE`\n\n\n## Methods\n\n### constructor\n\nCreates a new `Log` instance.\n\n`new Log({id})`\n\n\n### getPriority\n\n`log.getPriority()`\n\n\n### log\n\nLog a debug level message (uses `console.debug` if available)\n\n`log.log(message, ...args)`\n`log.log(priority, message, ...args)`\n`log.log({priority, message, args, ....options})`\n\nReturns: a function closure that should be called immediately.\n\n\n### info\n\nLog a normal message (uses `console.info` if available)\n\n`log.info(message, ...args)`\n`log.info(priority, message, ...args)`\n`log.info({priority, message, args, ....options})`\n\nReturns: a function closure that should be called immediately.\n\n\n### once\n\nLog a normal message, but only once, no console flooding\n\n`once(priority|opts, arg, ...args)`\n\nReturns: a function closure that should be called immediately.\n\n\n### probe\n\nLog a message with time since page load\n\n`log.probe(message, ...args)`\n`log.probe(priority, message, ...args)`\n`log.probe({priority, message, args, ....options})`\n\nReturns: a function closure that should be called immediately.\n\n\n### warn\n\nLogs a warning (uses the `console.warn` method if available). Logs each warning only once to avoid console flooding.\n\n`log.warn(message, ...args)`\n`log.warn({message, args, ....options})`\n\nReturns: a function closure that should be called immediately.\n\n\n### error\n\nPrint an error, using the console's error method\n\n`log.error(message, ...args)`\n`log.error({message, args, ....options})`\n\nReturns: a function closure that should be called immediately.\n\n\n### assert(condition : Boolean [, message: String])\n\nThrows an error with the supplied message (or a default message) if condition is false\n\n\n### deprecated\n\nGenerates a deprecation warning (using `log.warn`):\n\"`oldUsage` is deprecated and will be removed in a later version. Use `newUsage` instead.\"\n\n`log.deprecated(oldUsage, newUsage)`\n* `oldUsage` - name of deprecated function or parameter\n* `newUsage` - name of new function or parameter\n\nReturns: a function closure that should be called immediately.\n\n\n### table\n\nLogs a table (using `console.table` if available).\n\n`log.table(priority|opts, table)`\n\nReturns: a function closure that should be called immediately.\n\n\n### image\n\nLogs an image (under Chrome)\n\n`log.image({priority, image, message = '', scale = 1})`\n\n\n### settings\n\nLogs the current settings as a table\n\n`log.settings()`\n\n### get(setting)\n\nReturns the current value of setting\n\n`log.get('priority')`\n\n### set(setting, value)\n\nUpdates the value of setting\n\n`log.set('priority', 3)`\n\n### time\n\n`log.time(priority, label)`\n\n\n### timeEnd\n\n`log.timeEnd(priority, label)`\n\n\n### group\n\n`log.group(priority, label)`\n\n\n### groupCollapsed\n\n`log.group(priority, label)`\n\n\n### groupEnd\n\n`log.groupEnd(priority)`\n\n\n## Experimental APIs\n\n\n### withGroup\n\nProvides an exception safe way to run some code within a group\n\n`log.withGroup(priority, label, func)`\n\n\n### trace\n\nPrints a stack trace\n\n","slug":"docs/api-reference/log/log","title":"Log"},{"excerpt":"enableDOMLogging (experimental) A utility that takes console output and display a copy in the dom for easy debugging. Inspired by tap…","rawMarkdownBody":"# enableDOMLogging (experimental)\n\nA utility that takes console output and display a copy in the dom for easy debugging. Inspired by [tap-browser-color](https://github.com/kirbysayshi/tap-browser-color).\n\n\n## Usage\n\n```js\nimport {_enableDOMLogging as enableDOMLogging} from '@probe.gl/test-utils';\nenableDOMLogging();\n```\n\n\n## Function\n\n### enableDOMLogging(options : Any)\n\nTurn DOM logging on/off.\n\n* if `options` is not provided, enable DOM logging with default options.\n* if `options` is an object, enable DOM logging. The following options are available:\n  - `container` (DOMElement) - the container to log into. If not provided, will append a new `div` to the document.\n  - `getStyle` (Function) - called when the log updates to get the css styles object for the container.\n* if `options` is `false`, disable all DOM logging.\n","slug":"docs/api-reference/test-utils/log-to-dom","title":"enableDOMLogging (experimental)"},{"excerpt":"makeSpy A spy utility that wraps a function. The wrapper is invisible: when called the wrapper calls the original function and returns the…","rawMarkdownBody":"# makeSpy\n\nA spy utility that wraps a function. The wrapper is invisible: when called the wrapper calls the original function and returns the return value.\n\nHowever it also updates certain metadata that can be inspected later, that:\n* lets you determine if the wrapped function or method was actually called during exectution of other code.\n* allows you to inspect how many times it was called.\n\nSpies also have facilities for mocking, allowing the test suite to override the functions return value to trigger certain conditions.\n\nThere are also `restore` and `reset` methods that allows you to reset the test status.\n\n\n## Usage\n\nOverride function return value\n```js\nimport {makeSpy} from '@probe.gl/test-utils';\nconst spy = makeSpy(Class, 'method');\nspy.returns(false);\n// Call code that calls the wrapped method.\n```\n\n\n## Function\n\n### makeSpy\n\nSignatures\n* `spy()` - just an empty function\n* `spy(func)` - wraps a function\n* `spy(obj, func)` - wraps a method\n\nAttach a spy to the function. The spy has the following methods and fields\n * `called` - whether spy was called\n * `callCount` - number of calls\n * `restore()` - remove spy completely\n * `reset()` - reset call count\n\n\n## Methods and fields on the Wrapped Function\n\n### spy.called\n\nBoolean, true if function was called\n\n\n### spy.callCount\n\nNumber, number of times spy was called, `0` if not called\n\n\n### spy.reset()\n\nResets the `called` and `callCount` flags (to `false` and `0`).\n\n\n### spy.returns(returnValue)\n\nMakes the wrapper function return the given value without calling the wrapped function.\n\n\n### spy.restore()\n\nRemoves the spy from the function being spied on.\n\n","slug":"docs/api-reference/test-utils/make-spy","title":"makeSpy"},{"excerpt":"Stats A collection of statistic for tracking time or magnitude metrics. Usage Just create Stat objects (see  documentation) for various…","rawMarkdownBody":"# Stats\n\nA collection of statistic for tracking time or magnitude metrics.\n\n## Usage\n\nJust create Stat objects (see `Stat` documentation) for various metrics.\n\n```js\nconst stats = new Stats({id: 'my-stats'});\nconst memoryUsage = stats.get('Mem');\nconst executionTime = stats.get('Time');\nmemoryUsage.addCount(1024);\nexecutionTime.timeStart();\nexecutionTime.timeEnd();\n```\n\n## Methods\n\n### constructor\n\n`new Stats({id, stats})`\n\n* `id` (`String`) - the id of the `Stats` object.\n* `stats` (`Stat[] || Object[]`) - the list of stats. Each element in the stats could be either`Stat` object or `{name, type}` (type is optional, default is `count`);\n\n\n### get\n\nRetrieve a stat tracker. Create it if it doesn't already exist.\n\n`stats.get(name, type)`\n\n* `name` (`String`, required) - the name of the stat tracker.\n* `type` (`String`, optional) - the type of the stat tracker. Default is `count`.\n\nSupported types are described in [Stat](/docs/api-reference/log/stat.md)\n\nReturns the `Stat` object identified by `name`.\n\n\n### reset\n\nResets all stats.\n\n`stats.reset()`\n\n\n### forEach\n\nIterate over all stats.\n\n`stats.forEach(fn)`\n\n* `fn` (`Function`, required) - function to call on each `Stat` object.\n\n### getTable\n\nReturn stats in a format suitable for `console.table`\n\n`stats.getTable()`\n","slug":"docs/api-reference/log/stats","title":"Stats"},{"excerpt":"Stat A tracker for a single statistic. Usage Create a  instance using . There are two basic usage patterns,  and .\n usage involves the…","rawMarkdownBody":"# Stat\n\nA tracker for a single statistic.\n\n## Usage\n\nCreate a `Stat` instance using `Stats.get`. There are two basic usage patterns, `timer` and `counter`.\n`Timer` usage involves the methods `timeStart`, `timeEnd`, `addTime`, `getHz`, and `getAverageTime`:\n\n```js\nconst stats = new Stats({id: 'my-stats'});\nconst executionTime = stats.get('Time');\nexecutionTime.timeStart();\nexecutionTime.timeEnd();\nexecutionTime.addTime(16);\n\n// getHz and getAverageTime based on the\n// number of individual timings that were taken\nexecutionTime.getHz();\nexecutionTime.getAverageTime();\n```\n\n`Counter` usage involves the methods `incrementCount`, `decrementCount`, `addCount`, and `subtractCount`:\n\n```js\nconst stats = new Stats({id: 'my-stats'});\nconst memoryUsage = stats.get('Mem');\nmemoryUsage.incrementCount();\nmemoryUsage.decrementCount();\nmemoryUsage.addCount(1024);\nmemoryUsage.subtractCount(512);\n```\n\nFor time statistics, the `Stat` object can also define a sample window, to only update `count` or `time` after a given number of samples are taken:\n\n```js\nconst stats = new Stats({id: 'my-stats'});\nconst executionTime = stats.get('Time').setSampleSize(3);\nexecutionTime.addTime(1);\nexecutionTime.addTime(2);\n// `time` is still 0 at this point\nexecutionTime.getHz();          // => 0\nexecutionTime.getAverageTime(); // => 0\n\nexecutionTime.addTime(3);\n// Now `time` = 6\nexecutionTime.getAverageTime(); // => 2\nexecutionTime.addTime(1);\nexecutionTime.addTime(1);\nexecutionTime.addTime(1);\nexecutionTime.getAverageTime();       // => 1.5\nexecutionTime.getSampleAverageTime(); // => 1 (only from the last sample set)\n```\n\n## Properties\n\n### name : String\n\nName of the stat.\n\n\n### count : Number\n\nAccumulated count or number of timings.\n\n\n### time : Number\n\nAccumulated time from all timings.\n\n### lastTiming : Number\n\nLast timing taken.\n\n### lastSampleTime : Number\n\nTiming of the last completed set of samples.\n\n\n## Methods\n\n### constructor\n\n`new Stat(name, type)`\n\n* `name` (`String`) - the name of the stat.\n* `type` (`String`) - the type of the stat.\n\nSupported options:\n- `count` \n- `averageTime`\n- `totalTime`\n- `fps`\n- `memory`\n\n### incrementCount\n\nIncrease `count` by `1`.\n\n`stat.incrementCount()`\n\n\n### decrementCount\n\nDecrease `count` by `1`.\n\n`stat.decrementCount()`\n\n\n### addCount\n\nIncrease `count` by `value`.\n\n`stat.addCount(value)`\n\n* `value` (`Number`, required) - the amount to add to `count`.\n\n\n### subtractCount\n\nDecrease `count` by `value`.\n\n`stat.subtractCount(value)`\n\n* `value` (`Number`, required) - the amount to subtract from `count`.\n\n\n### timeStart\n\nStart a timer.\n\n`stat.timeStart()`\n\n\n### timeEnd\n\nEnd a timer. Time elapsed since the last `timeStart` is\nadded to `time` and `count` is incremented by `1`.\n\n`stat.timeEnd()`\n\n\n### addTime\n\nIncrease `time` by `value` and increment `count` by `1`.\n\n`stat.addTime(value)`\n\n* `value` (`Number`, required) - time in millisecons to add to `time`.\n\n\n### getHz\n\nCalculate the average number of timing events per second (i.e. `samples / (time * 1000)`.\n\n`stat.getHz()`\n\n\n### getAverageTime\n\nCalculate the average amount of time take per timing event in milliseconds (i.e. `time / samples`).\n\n`stat.getAverageTime()`\n\n### getAverageCount\n\nCalculate the average count per sampling (i.e. `count / samples`).\n\n`stat.getAverageCount()`\n\n### getSampleHz\n\nCalculate the average number of timing events per second (i.e. `samples / (time * 1000)` for the last completed set of samples.\n\n`stat.getHz()`\n\n\n### getSampleAverageTime\n\nCalculate the average amount of time take per timing event in milliseconds (i.e. `time / samples`) for the last completed set of samples.\n\n`stat.getAverageTime()`\n\n\n### getSampleAverageCount\n\nCalculate the average count per sampling (i.e. `count / samples`) for the last completed set of samples.\n\n`stat.getAverageTime()`\n\n\n\n\n","slug":"docs/api-reference/log/stat","title":"Stat"}]}}}